{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "EDI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nCtCD9Dmujnl",
        "p1901emZttS5",
        "5QARNOK8ttS6",
        "8Zioa_jlttS7",
        "zD8ZMUiGttS9",
        "3uT5BbMkttTA",
        "eUVV88BSttTD",
        "s07bxAeWttTD",
        "TO8woiLBttTF",
        "yi6OaY3httTH",
        "axlZU55tttTI"
      ],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhDYCeFEttSw"
      },
      "source": [
        "# Library for View Images in Google Colab\n",
        "from IPython.display import Image\n",
        "#Library for Data Preprocessing Analysing Visualizing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "#Library for Text Data Preprocessing \n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "# Library for Splitting Data into Training and Testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Library for converting text into vectors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Library for Machine Learning Models/ Estimators\n",
        "# Logisitic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Support Vector Machine\n",
        "from sklearn import svm\n",
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Random Forest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Library for Machine Learning Models/ Estimators Evaluation Pattern\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrQZro1tttS2"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Suicidal_Sentiment_Analysis/Tweets_Mix.csv\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "98xTk8BattS3",
        "outputId": "e6de1b29-4ab1-4aab-b462-d4e4fed73406"
      },
      "source": [
        "data.head(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>â youâ€™re stuck with me now iâ€™m not leav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>i wake up and just want to sleep forever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>@dotmariusz I'm a late bird  Mariusz - you fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>our friendly purge there is not a better way t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>this what you a saying many thieves and looter...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment                                             Tweets\n",
              "0          1  you dont have to be crazy to work here serious...\n",
              "1          0  Paw pawing my ass off smh...im starting to fee...\n",
              "2          1  and ppl better not act like threatening suicid...\n",
              "3          0  @juliaroy you are just a tumbling fool. Love it. \n",
              "4          0  Just gonna go shopping up Fosse Park with mate...\n",
              "5          1   â youâ€™re stuck with me now iâ€™m not leav...\n",
              "6          1           i wake up and just want to sleep forever\n",
              "7          0  @dotmariusz I'm a late bird  Mariusz - you fro...\n",
              "8          1  our friendly purge there is not a better way t...\n",
              "9          1  this what you a saying many thieves and looter..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCrnEB56ttS4",
        "outputId": "b46e09fe-0518-4176-8080-6d227447061d"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Sentiment  10000 non-null  int64 \n",
            " 1   Tweets     10000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 156.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggs4rXdMttS4",
        "outputId": "a00b5c2e-1b8e-411d-bf16-9d0293acf0e9"
      },
      "source": [
        "data['Sentiment'].value_counts()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5000\n",
              "0    5000\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCtCD9Dmujnl"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfT8ojhjttS4"
      },
      "source": [
        "# Writing Function to remove the mentions  URL's  and String with @\n",
        "def removeURL(text):\n",
        "    tweet_out = re.sub(r'@[A-Za-z0-9]+','',text)\n",
        "    re.sub('https?://[A-zA-z0-9]+','',text)\n",
        "    return tweet_out\n",
        "\n",
        "# Writing function to remove the non-numeric characters\n",
        "def removeNonAlphanumeric(text):\n",
        "    text_out = \"\".join([char for char in text if char not in string.punctuation])\n",
        "    return text_out"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svo2gpyOttS5"
      },
      "source": [
        "data[\"Tweet_No_URL\"]  = data[\"Tweets\"].apply(lambda x:removeURL(x))\n",
        "data[\"Tweet_No_Punc\"] = data[\"Tweet_No_URL\"].apply(lambda x:removeNonAlphanumeric(x))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "a_76th2EttS5",
        "outputId": "523c8f60-8c95-48a8-83cf-2fcb4240443f"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Tweet_No_URL</th>\n",
              "      <th>Tweet_No_Punc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smhim starting to feel b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool Love it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  ...                                      Tweet_No_Punc\n",
              "0          1  ...  you dont have to be crazy to work here serious...\n",
              "1          0  ...  Paw pawing my ass off smhim starting to feel b...\n",
              "2          1  ...  and ppl better not act like threatening suicid...\n",
              "3          0  ...              you are just a tumbling fool Love it \n",
              "4          0  ...  Just gonna go shopping up Fosse Park with mate...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1901emZttS5"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX4_CjsbttS6"
      },
      "source": [
        "def tokenization(text):\n",
        "    token = re.split('\\W+',text)\n",
        "    return token\n",
        "\n",
        "data [\"Tokens\"] = data[\"Tweet_No_Punc\"].apply(lambda x:tokenization(x))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "_cK3dTicttS6",
        "outputId": "2c3582b9-5519-404d-b46f-4fa9c0a2037f"
      },
      "source": [
        "data"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Tweet_No_URL</th>\n",
              "      <th>Tweet_No_Punc</th>\n",
              "      <th>Tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smhim starting to feel b...</td>\n",
              "      <td>[Paw, pawing, my, ass, off, smhim, starting, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool Love it</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0</td>\n",
              "      <td>@valxx http://twitpic.com/2w1uj - And the artw...</td>\n",
              "      <td>http://twitpic.com/2w1uj - And the artwork's ...</td>\n",
              "      <td>httptwitpiccom2w1uj  And the artworks by Bill...</td>\n",
              "      <td>[, httptwitpiccom2w1uj, And, the, artworks, by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>1</td>\n",
              "      <td>i just love reading that im worthless \\r\\n\\r\\...</td>\n",
              "      <td>i just love reading that im worthless \\r\\n\\r\\...</td>\n",
              "      <td>i just love reading that im worthless \\r\\n\\r\\...</td>\n",
              "      <td>[, i, just, love, reading, that, im, worthless...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0</td>\n",
              "      <td>Disneyland was great! ... Got to go and pick ...</td>\n",
              "      <td>Disneyland was great! ... Got to go and pick ...</td>\n",
              "      <td>Disneyland was great  Got to go and pick up t...</td>\n",
              "      <td>[, Disneyland, was, great, Got, to, go, and, p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>1</td>\n",
              "      <td>i hope i die in my sleep</td>\n",
              "      <td>i hope i die in my sleep</td>\n",
              "      <td>i hope i die in my sleep</td>\n",
              "      <td>[i, hope, i, die, in, my, sleep]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0</td>\n",
              "      <td>i dont want to live anymore</td>\n",
              "      <td>i dont want to live anymore</td>\n",
              "      <td>i dont want to live anymore</td>\n",
              "      <td>[i, dont, want, to, live, anymore]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Sentiment  ...                                             Tokens\n",
              "0             1  ...  [you, dont, have, to, be, crazy, to, work, her...\n",
              "1             0  ...  [Paw, pawing, my, ass, off, smhim, starting, t...\n",
              "2             1  ...  [and, ppl, better, not, act, like, threatening...\n",
              "3             0  ...  [, you, are, just, a, tumbling, fool, Love, it, ]\n",
              "4             0  ...  [Just, gonna, go, shopping, up, Fosse, Park, w...\n",
              "...         ...  ...                                                ...\n",
              "9995          0  ...  [, httptwitpiccom2w1uj, And, the, artworks, by...\n",
              "9996          1  ...  [, i, just, love, reading, that, im, worthless...\n",
              "9997          0  ...  [, Disneyland, was, great, Got, to, go, and, p...\n",
              "9998          1  ...                   [i, hope, i, die, in, my, sleep]\n",
              "9999          0  ...                 [i, dont, want, to, live, anymore]\n",
              "\n",
              "[10000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QARNOK8ttS6"
      },
      "source": [
        "#### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGo6a9V1ttS7"
      },
      "source": [
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def stemming (text):\n",
        "    out_text = [ps.stem(word) for word in text]\n",
        "    return out_text\n",
        "\n",
        "data['Stem'] = data['Tokens'].apply(lambda x:stemming(x))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "dz4Q4QUzttS7",
        "outputId": "b7d8a3f1-8844-4cee-dea0-d941aa3b99b1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Tweet_No_URL</th>\n",
              "      <th>Tweet_No_Punc</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazi, to, work, her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smhim starting to feel b...</td>\n",
              "      <td>[Paw, pawing, my, ass, off, smhim, starting, t...</td>\n",
              "      <td>[paw, paw, my, ass, off, smhim, start, to, fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threaten, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool Love it</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbl, fool, love, it, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "      <td>[just, gonna, go, shop, up, foss, park, with, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  ...                                               Stem\n",
              "0          1  ...  [you, dont, have, to, be, crazi, to, work, her...\n",
              "1          0  ...  [paw, paw, my, ass, off, smhim, start, to, fee...\n",
              "2          1  ...  [and, ppl, better, not, act, like, threaten, s...\n",
              "3          0  ...     [, you, are, just, a, tumbl, fool, love, it, ]\n",
              "4          0  ...  [just, gonna, go, shop, up, foss, park, with, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zioa_jlttS7"
      },
      "source": [
        "#### Lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-wCX2ZAu3Hg",
        "outputId": "a9fed073-9911-4291-d98c-0e27384b04ab"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nUzFDXtttS7",
        "outputId": "1ee786f8-e87c-4047-b152-27a83daa08e6"
      },
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "    out_text = [wn.lemmatize(word) for word in text]\n",
        "    return out_text\n",
        "\n",
        "data['Lem'] =data['Tokens'].apply(lambda x:lemmatize(x))\n",
        "\n",
        "data['Lem'].head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [you, dont, have, to, be, crazy, to, work, her...\n",
              "1    [Paw, pawing, my, as, off, smhim, starting, to...\n",
              "2    [and, ppl, better, not, act, like, threatening...\n",
              "3    [, you, are, just, a, tumbling, fool, Love, it, ]\n",
              "4    [Just, gonna, go, shopping, up, Fosse, Park, w...\n",
              "Name: Lem, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "FedtlASZttS8",
        "outputId": "1e246925-a806-46cb-f980-d63270e14e37"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Tweet_No_URL</th>\n",
              "      <th>Tweet_No_Punc</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Stem</th>\n",
              "      <th>Lem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazi, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smhim starting to feel b...</td>\n",
              "      <td>[Paw, pawing, my, ass, off, smhim, starting, t...</td>\n",
              "      <td>[paw, paw, my, ass, off, smhim, start, to, fee...</td>\n",
              "      <td>[Paw, pawing, my, as, off, smhim, starting, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threaten, s...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool Love it</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbl, fool, love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "      <td>[just, gonna, go, shop, up, foss, park, with, ...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  ...                                                Lem\n",
              "0          1  ...  [you, dont, have, to, be, crazy, to, work, her...\n",
              "1          0  ...  [Paw, pawing, my, as, off, smhim, starting, to...\n",
              "2          1  ...  [and, ppl, better, not, act, like, threatening...\n",
              "3          0  ...  [, you, are, just, a, tumbling, fool, Love, it, ]\n",
              "4          0  ...  [Just, gonna, go, shopping, up, Fosse, Park, w...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD8ZMUiGttS9"
      },
      "source": [
        "#### Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZy4e3SWttS9",
        "outputId": "b99681d1-9406-4dd3-c316-71d89a2c8054"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz4Y4bp2ttS9"
      },
      "source": [
        "def remove_stopWords(token_list):\n",
        "    text_out = [word for word in token_list if word not in stopwords]\n",
        "    return text_out\n",
        "\n",
        "data['StopRemove'] = data['Lem'].apply(lambda x:remove_stopWords(x))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vTn9Gq_FttS9",
        "outputId": "e020cbd5-ffea-4f8c-8d71-ed50bdfeff2b"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Tweet_No_URL</th>\n",
              "      <th>Tweet_No_Punc</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Stem</th>\n",
              "      <th>Lem</th>\n",
              "      <th>StopRemove</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazi, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "      <td>[dont, crazy, work, seriously, illegal, requir...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smhim starting to feel b...</td>\n",
              "      <td>[Paw, pawing, my, ass, off, smhim, starting, t...</td>\n",
              "      <td>[paw, paw, my, ass, off, smhim, start, to, fee...</td>\n",
              "      <td>[Paw, pawing, my, as, off, smhim, starting, to...</td>\n",
              "      <td>[Paw, pawing, smhim, starting, feel, better, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threaten, s...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "      <td>[ppl, better, act, like, threatening, suicide,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool Love it</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbl, fool, love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "      <td>[, tumbling, fool, Love, ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "      <td>[just, gonna, go, shop, up, foss, park, with, ...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "      <td>[Just, gonna, go, shopping, Fosse, Park, mate,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  ...                                         StopRemove\n",
              "0          1  ...  [dont, crazy, work, seriously, illegal, requir...\n",
              "1          0  ...     [Paw, pawing, smhim, starting, feel, better, ]\n",
              "2          1  ...  [ppl, better, act, like, threatening, suicide,...\n",
              "3          0  ...                         [, tumbling, fool, Love, ]\n",
              "4          0  ...  [Just, gonna, go, shopping, Fosse, Park, mate,...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Y00alowVgJ"
      },
      "source": [
        "def final_join(token):\n",
        "    document = \" \".join([word for word in token if not word.isdigit()])\n",
        "    return document\n",
        "\n",
        "data['FinalJoin'] = data['StopRemove'].apply(lambda x:final_join(x))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "81Z9cSuCweg9",
        "outputId": "b44f6658-de76-4d9e-ba05-42c0fbf585ad"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweets</th>\n",
              "      <th>Tweet_No_URL</th>\n",
              "      <th>Tweet_No_Punc</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Stem</th>\n",
              "      <th>Lem</th>\n",
              "      <th>StopRemove</th>\n",
              "      <th>FinalJoin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>you dont have to be crazy to work here serious...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazi, to, work, her...</td>\n",
              "      <td>[you, dont, have, to, be, crazy, to, work, her...</td>\n",
              "      <td>[dont, crazy, work, seriously, illegal, requir...</td>\n",
              "      <td>dont crazy work seriously illegal require dont...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smh...im starting to fee...</td>\n",
              "      <td>Paw pawing my ass off smhim starting to feel b...</td>\n",
              "      <td>[Paw, pawing, my, ass, off, smhim, starting, t...</td>\n",
              "      <td>[paw, paw, my, ass, off, smhim, start, to, fee...</td>\n",
              "      <td>[Paw, pawing, my, as, off, smhim, starting, to...</td>\n",
              "      <td>[Paw, pawing, smhim, starting, feel, better, ]</td>\n",
              "      <td>Paw pawing smhim starting feel better</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>and ppl better not act like threatening suicid...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threaten, s...</td>\n",
              "      <td>[and, ppl, better, not, act, like, threatening...</td>\n",
              "      <td>[ppl, better, act, like, threatening, suicide,...</td>\n",
              "      <td>ppl better act like threatening suicide result...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@juliaroy you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool. Love it.</td>\n",
              "      <td>you are just a tumbling fool Love it</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbl, fool, love, it, ]</td>\n",
              "      <td>[, you, are, just, a, tumbling, fool, Love, it, ]</td>\n",
              "      <td>[, tumbling, fool, Love, ]</td>\n",
              "      <td>tumbling fool Love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>Just gonna go shopping up Fosse Park with mate...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "      <td>[just, gonna, go, shop, up, foss, park, with, ...</td>\n",
              "      <td>[Just, gonna, go, shopping, up, Fosse, Park, w...</td>\n",
              "      <td>[Just, gonna, go, shopping, Fosse, Park, mate,...</td>\n",
              "      <td>Just gonna go shopping Fosse Park mate Got ï ½...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sentiment  ...                                          FinalJoin\n",
              "0          1  ...  dont crazy work seriously illegal require dont...\n",
              "1          0  ...             Paw pawing smhim starting feel better \n",
              "2          1  ...  ppl better act like threatening suicide result...\n",
              "3          0  ...                                tumbling fool Love \n",
              "4          0  ...  Just gonna go shopping Fosse Park mate Got ï ½...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uT5BbMkttTA"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUVV88BSttTD"
      },
      "source": [
        "#### Splitting of Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Ww-XFjttTD"
      },
      "source": [
        "X = data['FinalJoin']\n",
        "y= data['Sentiment']\n",
        "cv = TfidfVectorizer(min_df=1,stop_words='english')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-RbCKD6ttTD"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20,random_state=0)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAR-ktCUxkuY",
        "outputId": "22684f9b-83f2-4261-e905-61bb6b7980da"
      },
      "source": [
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 2000, 8000, 2000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y0GR3s5x1JP"
      },
      "source": [
        "X_train = cv.fit_transform(X_train)\n",
        "X_test = cv.transform(X_test)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s07bxAeWttTD"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A0Tjr3httTE"
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "\n",
        "logreg = logreg.fit(X_train,y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs46EQelttTE",
        "outputId": "5cbdc066-c176-41ab-8751-bee05ab5c96c"
      },
      "source": [
        "logreg.score(X_train,y_train)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.97625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twWLKlzQttTE",
        "outputId": "b1f0d6b4-60bb-431d-bbb4-6879c59a28f7"
      },
      "source": [
        "logreg.score(X_test,y_test)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx7EKT5QttTF",
        "outputId": "8898b916-9b95-48fe-b42a-db4e6c3127c9"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       976\n",
            "           1       0.95      0.96      0.96      1024\n",
            "\n",
            "    accuracy                           0.95      2000\n",
            "   macro avg       0.96      0.95      0.95      2000\n",
            "weighted avg       0.96      0.95      0.95      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2OtkAM5ttTF",
        "outputId": "c93b1844-c87c-4fac-ce82-5fe9f35138f5"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[927  49]\n",
            " [ 41 983]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO8woiLBttTF"
      },
      "source": [
        "#### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWzkH5S5ttTF"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=100)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SFNJWJKttTG"
      },
      "source": [
        "clf.fit(X_train,y_train);"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PjjyYpHttTG"
      },
      "source": [
        "y_pred = clf.predict(X_test)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpbnL2EcttTG",
        "outputId": "0bfd2f7d-7acc-43c6-c4de-75618b0b6419"
      },
      "source": [
        "clf.score(X_train,y_train)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP3MoC3PttTG",
        "outputId": "d5366d3c-e8b5-4796-dda1-32819b7605c4"
      },
      "source": [
        "clf.score(X_test,y_test)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9635"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bXcwTKzttTG",
        "outputId": "6a8b256a-8a8b-4c82-82b2-345c075ddc51"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       976\n",
            "           1       0.95      0.98      0.97      1024\n",
            "\n",
            "    accuracy                           0.96      2000\n",
            "   macro avg       0.96      0.96      0.96      2000\n",
            "weighted avg       0.96      0.96      0.96      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlzA5fIDttTG",
        "outputId": "cc4906f1-eed3-451d-c4d8-2fc99e6d5a35"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 919   57]\n",
            " [  16 1008]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi6OaY3httTH"
      },
      "source": [
        "#### Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdK2b9AYttTI"
      },
      "source": [
        "class_linear = svm.SVC(kernel='linear')\n",
        "class_linear.fit(X_train,y_train);"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cai71GRattTI"
      },
      "source": [
        "y_pred = class_linear.predict(X_test)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7s1EegEttTI",
        "outputId": "415712f9-80e8-4eb7-ea55-ab6a21eee093"
      },
      "source": [
        "class_linear.score(X_train,y_train)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.991875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhsLxJsvttTI",
        "outputId": "cd66ca37-b115-404e-8101-2568e9c04139"
      },
      "source": [
        "class_linear.score(X_test,y_test)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9575"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvJ6fjYu0Mnd",
        "outputId": "5efca071-bdd7-43e8-fd51-6cf9247f1a46"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96       976\n",
            "           1       0.94      0.98      0.96      1024\n",
            "\n",
            "    accuracy                           0.96      2000\n",
            "   macro avg       0.96      0.96      0.96      2000\n",
            "weighted avg       0.96      0.96      0.96      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBcbMoms0SPm",
        "outputId": "0cf6c25b-c519-4c36-c31d-84df5b41dbd1"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 915   61]\n",
            " [  24 1000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axlZU55tttTI"
      },
      "source": [
        "#### Navie Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejQdaavGttTJ"
      },
      "source": [
        "mnb = MultinomialNB()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCynfkrPttTJ"
      },
      "source": [
        "mnb.fit(X_train,y_train);"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVY0pzZttTK"
      },
      "source": [
        "y_pred = mnb.predict(X_test);"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-3TIwFbttTK",
        "outputId": "9ba9b143-efe1-4723-c012-f9ebcd84439f"
      },
      "source": [
        "mnb.score(X_train,y_train)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.961125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjLXisCQttTK",
        "outputId": "7b981859-54cd-4652-8ba1-bea905b73136"
      },
      "source": [
        "mnb.score(X_test,y_test)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBS61V2YttTK",
        "outputId": "1db1ec73-ca76-4af0-e7f5-7896765fc32f"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87       976\n",
            "           1       0.82      0.98      0.90      1024\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.90      0.88      0.88      2000\n",
            "weighted avg       0.90      0.88      0.88      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiTI1YQYttTK",
        "outputId": "1a7d2392-ff16-4700-95c5-47deeb60ca29"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 758  218]\n",
            " [  17 1007]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlCDwNkYz3bn"
      },
      "source": [
        "**Accuracy of All 4**\n",
        "\n",
        "1. Logistic Regression: 95.50%\n",
        "2. Random Forest: 96.35%\n",
        "3. Support Vector Machine: 95.75%\n",
        "4. Naive Bayes: 88.25%"
      ]
    }
  ]
}